episode_reward_max,episode_reward_min,episode_reward_mean,episode_len_mean,episodes_this_iter,num_healthy_workers,timesteps_total,timesteps_this_iter,agent_timesteps_total,done,episodes_total,training_iteration,trial_id,experiment_id,date,timestamp,time_this_iter_s,time_total_s,pid,hostname,node_ip,time_since_restore,timesteps_since_restore,iterations_since_restore,policy_reward_min/policy_red_,policy_reward_min/policy_blue_,policy_reward_max/policy_red_,policy_reward_max/policy_blue_,policy_reward_mean/policy_red_,policy_reward_mean/policy_blue_,hist_stats/episode_reward,hist_stats/episode_lengths,hist_stats/policy_policy_red__reward,hist_stats/policy_policy_blue__reward,sampler_perf/mean_raw_obs_processing_ms,sampler_perf/mean_inference_ms,sampler_perf/mean_action_processing_ms,sampler_perf/mean_env_wait_ms,sampler_perf/mean_env_render_ms,timers/sample_time_ms,timers/sample_throughput,timers/load_time_ms,timers/load_throughput,timers/learn_time_ms,timers/learn_throughput,timers/update_time_ms,info/num_steps_sampled,info/num_agent_steps_sampled,info/num_steps_trained,info/num_agent_steps_trained,perf/cpu_util_percent,perf/ram_util_percent,info/learner/policy_red_/learner_stats/allreduce_latency,info/learner/policy_red_/learner_stats/cur_kl_coeff,info/learner/policy_red_/learner_stats/cur_lr,info/learner/policy_red_/learner_stats/total_loss,info/learner/policy_red_/learner_stats/policy_loss,info/learner/policy_red_/learner_stats/vf_loss,info/learner/policy_red_/learner_stats/vf_explained_var,info/learner/policy_red_/learner_stats/kl,info/learner/policy_red_/learner_stats/entropy,info/learner/policy_red_/learner_stats/entropy_coeff,info/learner/policy_blue_/learner_stats/allreduce_latency,info/learner/policy_blue_/learner_stats/cur_kl_coeff,info/learner/policy_blue_/learner_stats/cur_lr,info/learner/policy_blue_/learner_stats/total_loss,info/learner/policy_blue_/learner_stats/policy_loss,info/learner/policy_blue_/learner_stats/vf_loss,info/learner/policy_blue_/learner_stats/vf_explained_var,info/learner/policy_blue_/learner_stats/kl,info/learner/policy_blue_/learner_stats/entropy,info/learner/policy_blue_/learner_stats/entropy_coeff
538.8,405.0,479.30588235294124,241.0,17,1,4097,0,9133,True,17,1,6874c_00000,ee03adab8fb24867ae01eaa9ca981932,2023-03-10_02-23-22,1678433002,13.379617929458618,13.379617929458618,201412,DESKTOP-3HT5ULL,127.0.0.1,13.379617929458618,0,1,114.1,57.0,184.89999999999998,121.5,150.3264705882353,89.3264705882353,"[486.29999999999995, 466.20000000000005, 490.6, 521.1, 478.1, 514.3, 538.8, 518.7, 443.20000000000005, 490.40000000000003, 512.5999999999999, 496.0, 487.5, 405.0, 460.9, 415.1, 423.4000000000001]","[241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241, 241]","[142.65, 132.65, 146.65, 155.65, 133.25, 173.25, 141.55, 152.55, 173.95, 150.95, 169.85, 168.85, 162.5, 139.5, 157.0, 158.0, 125.6, 119.6, 159.3, 156.3, 184.89999999999998, 148.89999999999998, 180.0, 176.0, 174.25, 168.25, 141.5, 143.5, 137.55, 156.55, 116.45, 130.45, 114.1, 119.1]","[107.5, 103.5, 86.45, 77.45, 98.55, 85.55, 105.5, 121.5, 80.6, 72.6, 75.8, 99.8, 120.4, 116.4, 103.85, 99.85, 88.0, 110.0, 82.4, 92.4, 84.4, 94.4, 74.0, 66.0, 70.0, 75.0, 57.0, 63.0, 85.4, 81.4, 88.6, 79.6, 97.1, 93.1]",0.1742914282676358,1.8222340727620383,0.062277923274936184,0.5540463795250017,0.0,10798.899,379.391,55.056,74415.657,2556.411,1602.637,3.472,4097,9133,4097,9133,30.773684210526312,59.13157894736843,0.0,0.2,0.0005,4712.65830078125,-0.16685735881328584,4712.8455078125,0.0032231688499450685,6.360589674889172e-07,2.0302993774414064,0.01,0.0,0.2,0.0005,1681.4438720703124,0.04135749191045761,1681.4232421875,0.0031859636306762694,0.0002632924024867672,2.0890088081359863,0.01
